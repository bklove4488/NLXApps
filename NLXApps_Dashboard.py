import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.interpolate import griddata
from sklearn.cluster import KMeans  # ë ˆì´ì–´ ë¶„ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€

# --- [1] ë°ì´í„° ì „ì²˜ë¦¬ ë° ë ˆì´ì–´ ë¶„ì„ ë¡œì§ ---
def process_data(df, scale_factor, apply_iqr, apply_pitch_iqr):
    df.columns = [c.strip() for c in df.columns]
    
    # ë°ì´í„° íƒ€ì… íŒë³„
    if 'Height' in df.columns: d_type, target = "Height", "Height"
    elif 'Radius' in df.columns: d_type, target = "Radius", "Radius"
    elif 'Shift_Norm' in df.columns: d_type, target = "Shift", "Shift_Norm"
    else: return None, None

    # [ì¶”ê°€] ë ˆì´ì–´ ìë™ ë¶„ì„ (Z-Position ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§)
    # Zê°’ì˜ ì°¨ì´ê°€ ë¯¸ì„¸í•˜ë¯€ë¡œ í´ëŸ¬ìŠ¤í„°ë§ì„ í†µí•´ ì¸µì„ êµ¬ë¶„í•©ë‹ˆë‹¤.
    z_values = df['Bump_Center_Z'].values.reshape(-1, 1)
    
    # ì—˜ë³´ìš° í¬ì¸íŠ¸ ëŒ€ì‹  ìµœëŒ€ 5ê°œ ì¸µê¹Œì§€ íƒìƒ‰í•˜ì—¬ ìµœì ì˜ ì¸µ ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ë¡œì§)
    # ì‹¤ë¬´ì ìœ¼ë¡œëŠ” ì‚¬ìš©ìê°€ ì¸µ ìˆ˜ë¥¼ ì…ë ¥í•˜ê²Œ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    n_clusters = 1
    if len(df) > 10:
        # Zê°’ì˜ ê³ ìœ ê°’ ë²”ìœ„ë¥¼ ë³´ê³  ëŒ€ëµì ì¸ ì¸µìˆ˜ ì¶”ì • (ì°¨ì´ê°€ 0.005 ì´ìƒì¼ ë•Œ êµ¬ë¶„ ë“±)
        z_range = np.ptp(df['Bump_Center_Z'])
        if z_range > 0.01: n_clusters = 2 # ì˜ˆì‹œ ì„ê³„ì¹˜
        if z_range > 0.05: n_clusters = 3
    
    # ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ ì¼ë‹¨ 1~5ì¸µ ì‚¬ì´ì—ì„œ ìë™ í• ë‹¹í•˜ê±°ë‚˜ 
    # ì•„ë˜ ë©”ì¸ ë£¨í”„ì—ì„œ ì‚¬ìš©ìê°€ ì§€ì •í•œ n_layersë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    # ê¸°ë³¸ ë‹¨ìœ„ ë³€í™˜
    df['X'] = df['Bump_Center_X'] * scale_factor
    df['Y'] = df['Bump_Center_Y'] * scale_factor
    df['Z_um'] = df['Bump_Center_Z'] * scale_factor
    df['Value'] = df[target] * scale_factor
    
    # 1ì°¨: ë©”ì¸ Value IQR ì œê±°
    df_clean = df[df['Value'] != 0].copy()
    if apply_iqr:
        q1, q3 = df_clean['Value'].quantile([0.25, 0.75])
        iqr = q3 - q1
        df_clean = df_clean[(df_clean['Value'] >= q1 - 1.5 * iqr) & (df_clean['Value'] <= q3 + 1.5 * iqr)]

    # 2ì°¨: Pitch ê³„ì‚°
    df_clean['Y_grid'] = df_clean['Y'].round(0)
    df_clean = df_clean.sort_values(by=['Y_grid', 'X'])
    df_clean['X_Pitch'] = df_clean.groupby('Y_grid')['X'].diff()

    df_clean['X_grid'] = df_clean['X'].round(0)
    df_clean = df_clean.sort_values(by=['X_grid', 'Y'])
    df_clean['Y_Pitch'] = df_clean.groupby('X_grid')['Y'].diff()

    # 3ì°¨: Pitch IQR í•„í„°ë§
    if apply_pitch_iqr:
        for col in ['X_Pitch', 'Y_Pitch']:
            p_data = df_clean[col].dropna()
            if not p_data.empty:
                pq1, pq3 = p_data.quantile([0.25, 0.75])
                piqr = pq3 - pq1
                df_clean.loc[(df_clean[col] < pq1 - 1.5 * piqr) | (df_clean[col] > pq3 + 1.5 * piqr), col] = np.nan

    return df_clean, d_type

# --- [2] UI êµ¬ì„± ---
st.set_page_config(page_title="NLX Multi-Layer Analyzer", layout="wide")
st.title("ğŸ”¬ NLX Bump Analysis Dashboard (Layer Analysis)")

st.sidebar.header("ğŸ“ Data & Layer Settings")
uploaded_files = st.sidebar.file_uploader("Upload CSV Files", type=['csv'], accept_multiple_files=True)
scale = st.sidebar.number_input("Global Scale Factor", value=1000)

# [ì¶”ê°€] ë ˆì´ì–´ ë¶„ë¦¬ ì„¤ì •
n_layers = st.sidebar.slider("Number of expected layers (Z-axis)", 1, 5, 1)

st.sidebar.subheader("ğŸ›¡ï¸ Outlier Removal Settings")
use_val_iqr = st.sidebar.checkbox("Apply IQR to Value", value=True)
use_pitch_iqr = st.sidebar.checkbox("Apply IQR to Pitch", value=True)

if uploaded_files:
    all_data = []
    
    for file in uploaded_files:
        raw_df = pd.read_csv(file)
        p_df, d_type = process_data(raw_df, scale, use_val_iqr, use_pitch_iqr)
        
        if p_df is not None:
            # Zì¶• í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰ (ë ˆì´ì–´ í• ë‹¹)
            if n_layers > 1:
                kmeans = KMeans(n_clusters=n_layers, random_state=42)
                p_df['Layer'] = kmeans.fit_predict(p_df[['Bump_Center_Z']])
                # Zê°’ í‰ê·  ìˆœì„œëŒ€ë¡œ ë ˆì´ì–´ ì´ë¦„ ì¬ì •ë ¬ (0ì¸µì´ ê°€ì¥ ë‚®ì€ ì¸µì´ ë˜ë„ë¡)
                layer_order = p_df.groupby('Layer')['Bump_Center_Z'].mean().sort_values().index
                layer_map = {old: new for new, old in enumerate(layer_order)}
                p_df['Layer'] = p_df['Layer'].map(layer_map)
            else:
                p_df['Layer'] = 0
                
            p_df['Source'] = file.name
            all_data.append(p_df)

    combined_df = pd.concat(all_data)

    # ë ˆì´ì–´ í•„í„°ë§ UI
    st.sidebar.markdown("---")
    unique_layers = sorted(combined_df['Layer'].unique())
    selected_layer = st.sidebar.selectbox("Select Layer to View", ["All Layers"] + [f"Layer {i}" for i in unique_layers])

    # ë°ì´í„° í•„í„°ë§ ì‹¤í–‰
    if selected_layer != "All Layers":
        layer_num = int(selected_layer.split(" ")[1])
        display_df = combined_df[combined_df['Layer'] == layer_num]
    else:
        display_df = combined_df

    # ìƒë‹¨ ìš”ì•½ ìš”ì•½
    st.subheader(f"ğŸ“Š Statistics Summary ({selected_layer})")
    summary_list = []
    for src in display_df['Source'].unique():
        sub = display_df[display_df['Source'] == src]
        summary_list.append({
            "File": src, "Avg": sub['Value'].mean(), "3-Sigma": sub['Value'].std()*3,
            "Count": len(sub)
        })
    st.dataframe(pd.DataFrame(summary_list))

    # [ì´í›„ ì‹œê°í™” ë¡œì§ì€ display_dfë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ì§„í–‰...]
    # (ìƒëµ: ê¸°ì¡´ ì½”ë“œì˜ ì‹œê°í™” ë¶€ë¶„ì—ì„œ plot_dfë¥¼ display_df ê¸°ë°˜ìœ¼ë¡œ í•„í„°ë§í•˜ì—¬ ì‚¬ìš©)